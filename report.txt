**House Keeping**
Timing reports are output from the Measure-Command utility on windows 11, these are in the timings folder.
GuitarDry.wav and bigHall.wav were used for all timings.
all output wav files are in the outputs folder

The baseline version can be found in convolveBaseline.cpp
Baseline Version Time: 823738.9601ms

**Optimizations**
The first optimization I did was an algorithm-based optimization.
I chose to use the overlap-add algorithm from p.311-318 in the Smith text, and I used the four1 FFT that we were given.
this version can be found at https://github.com/E-Gantz/501A4/blob/4d924f5712a7861c261599857af767ff1202c9a5/convolve.cpp
Algorithm optimized time: 3542.7792ms

However, I want to note that if one wanted to optimize the baseline/time-domain convolution before replacing it entirely with frequency-domain convolution, they could swap the order of the for loops.
This is because the outer loop is for each sample in the input, and the inner for loop is for each sample in the filter.
In most cases the filter will be significantly shorter than the input, and thus it would be an improvement to have the outer loop be the filter. i.e. smaller loop on the outside.

Next I started using a profiler to see where I could do some manual tuning.
To do this I used gprof and compiled with "g++ -Wall -pg -no-pie -o convolve convolve.cpp"
    note: the -no-pie flag is there because I was getting empty gprof output which is apparently a gcc bug: https://stackoverflow.com/questions/42620074/gprof-produces-empty-output
At this point I also started using the diff command to do regression testing to compare output files.

The gprof output claimed that 75% of output time was in four1, which I was too scared to touch, so I just looked through the code to find things to optimize.
My first manual tuning was to remove unnecessary code.
First I found that in sampleToDouble I was checking if the input value was negative and doing an absolute value calculation, so i just replaced that with "return double(value) / (double)32767.0;" to cut down on if statement calls and unnecessary operations.
note that this method is run from a loop, so this effectively 'unswitches' the loop by removing if statements within the loop.
I also removed the final print statement, as it was unnecessary I/O, and the zeroPadding method as i had already inlined it.
this version can be found at https://github.com/E-Gantz/501A4/blob/ea405d43946d6e87c9a36f0ffac8fb2f53d58cd9/convolve.cpp
manual tuning time: 1503.1768ms

Next I looked for other functions I could inline, but found none, and values that were being recalculated that I could cache.
The most obvious one was M-1, so I cached that to use throughout my convolve method.
I also found that I was using 2*paddingSize a lot which not only is a repeated operation, but a repeated multiplication which is extra smelly, so I cached that as well.
note that by 'cached' I mean U put the result in a variable and used the variable instead of the calculation. I'm not sure if you can change the system cache in C++ in a similar way to manually using the registers, but I didn't do anything of that sort.
Another optimization I had done earlier was changing from tracking the position in the input and output vectors via an offset variable (i*number of samples per segment, i goes from 0 to number of segments-1) to 
just tracking the position using the inputPos and outputPos variables, which removes one multiplication per loop.
this version can be found at https://github.com/E-Gantz/501A4/blob/9c4f2d991b5313df9b19c18216534599104b0905/convolve.cpp
manual tuning time: 1434.0383ms

I then noticed I had a lot of little for loops within the convolve function, and looked for some that I could jam together.
I had two consecutive "for (int j=0; j<paddingSize; j++)" loops, one to fill the output vector from the real part of the post IFFT vector, and one to scale the values, so I combined these into one loop.
at this point four1 had gone up to over 80% of the run time according to gprof, which shows that I increased the speed of the other parts.
Another jamming could be combining the 'set everything to 0' and 'fill in the real parts' loops that I use before the first two four1 calls, but I had issues with doing both things in one loop earlier so I'm going to leave them as is.
this version can be found at https://github.com/E-Gantz/501A4/blob/5d3ab58e6d4cbcd7b88b5c5b0c22e081cd0e508d/convolve.cpp
manual tuning time: 1322.2385ms

A further manual tuning could be replacing some operations, such as finding the nearest power of 2, with bitwise operations rather than with calculations.
However, I'm not very familiar with bitwise operations, so I'm going to only mention this and not attempt it.

My final optimization was a compiler optimization, I changed from compiling with "g++ -o convolve convolve.cpp" to "g++ -O3 -o convolve convolve.cpp"
compiler optimized time: 1639.857ms
I find it interesting that compiling with -03 produces a slightly slower program than compiling normally